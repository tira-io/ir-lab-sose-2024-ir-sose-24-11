{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BM25 + SDM Model trial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Import libraries\n",
    "\n",
    "No additional libraries apart from the baselines.\n",
    "Ensure pyterrier is loaded, confirm the pt is initialized\n",
    "Persist and normalize run, further writing of the result in out txt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTerrier 0.10.0 has loaded Terrier 5.8 (built by craigm on 2023-11-01 18:05) and terrier-helper 0.0.8\n",
      "\n",
      "No etc/terrier.properties, using terrier.default.properties for bootstrap configuration.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I will use a small hardcoded example located in ./iranthology-dataset-tira.\n"
     ]
    }
   ],
   "source": [
    "import pyterrier as pt\n",
    "import pandas as pd\n",
    "from tira.third_party_integrations import ensure_pyterrier_is_loaded, get_input_directory_and_output_directory, persist_and_normalize_run\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from tira.rest_api_client import Client\n",
    "\n",
    "ensure_pyterrier_is_loaded()\n",
    "input_directory, output_directory = get_input_directory_and_output_directory('./iranthology-dataset-tira')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tira = Client()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Load the data and create the index \n",
    "Index already built in PT format from TIRA. We will be using the IR and ACL anthology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The dataset: the union of the IR Anthology and the ACL Anthology\n",
    "# This line creates an IRDSDataset object and registers it under the name provided as an argument.\n",
    "pt_dataset = pt.get_dataset('irds:ir-lab-sose-2024/ir-acl-anthology-20240504-training')\n",
    "# A (pre-built) PyTerrier index loaded from TIRA\n",
    "index = tira.pt.index('ir-lab-sose-2024/tira-ir-starter/Index (tira-ir-starter-pyterrier)', pt_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 3. Create the retrieval pipeline. In this case is our baseline BM25 model trying to be improved with sdm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdm = pt.rewrite.SDM()\n",
    "bm25 = pt.BatchRetrieve(index, wmodel=\"BM25\", verbose=True)\n",
    "\n",
    "retrieval_pipeline = sdm >> bm25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4. Create the run. \n",
    "Do the retrieval with the smd improvement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First, we have a short look at the first three topics:\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print('First, we have a short look at the first three topics:')\n",
    "\n",
    "topics = pt_dataset.get_topics('text').head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now we do the retrieval...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BR(BM25):   0%|          | 0/3 [00:00<?, ?q/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18:32:03.657 [main] ERROR org.terrier.querying.LocalManager - Problem running Matching, returning empty result set as query 1\n",
      "java.io.IOException: This index does not support blocks\n",
      "\tat org.terrier.matching.matchops.PhraseOp.createFinalPostingIterator(PhraseOp.java:85)\n",
      "\tat org.terrier.matching.matchops.MultiTermOp.getPostingIterator(MultiTermOp.java:131)\n",
      "\tat org.terrier.matching.matchops.MultiTermOp.getMatcher(MultiTermOp.java:147)\n",
      "\tat org.terrier.matching.PostingListManager.<init>(PostingListManager.java:304)\n",
      "\tat org.terrier.matching.PostingListManager.<init>(PostingListManager.java:282)\n",
      "\tat org.terrier.matching.daat.Full.match(Full.java:88)\n",
      "\tat org.terrier.querying.LocalManager$ApplyLocalMatching.process(LocalManager.java:518)\n",
      "\tat org.terrier.querying.LocalManager.runSearchRequest(LocalManager.java:895)\n",
      "Caused by: java.lang.ClassCastException: class org.terrier.structures.postings.bit.FieldIterablePosting cannot be cast to class org.terrier.structures.postings.BlockPosting (org.terrier.structures.postings.bit.FieldIterablePosting and org.terrier.structures.postings.BlockPosting are in unnamed module of loader 'app')\n",
      "\tat org.terrier.structures.postings.PhraseIterablePosting.<init>(PhraseIterablePosting.java:58)\n",
      "\tat org.terrier.matching.matchops.PhraseOp.createFinalPostingIterator(PhraseOp.java:83)\n",
      "\t... 7 common frames omitted\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BR(BM25):  33%|███▎      | 1/3 [00:00<00:00,  7.46q/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18:32:03.702 [main] ERROR org.terrier.querying.LocalManager - Problem running Matching, returning empty result set as query 2\n",
      "java.io.IOException: This index does not support blocks\n",
      "\tat org.terrier.matching.matchops.PhraseOp.createFinalPostingIterator(PhraseOp.java:85)\n",
      "\tat org.terrier.matching.matchops.MultiTermOp.getPostingIterator(MultiTermOp.java:131)\n",
      "\tat org.terrier.matching.matchops.MultiTermOp.getMatcher(MultiTermOp.java:147)\n",
      "\tat org.terrier.matching.PostingListManager.<init>(PostingListManager.java:304)\n",
      "\tat org.terrier.matching.PostingListManager.<init>(PostingListManager.java:282)\n",
      "\tat org.terrier.matching.daat.Full.match(Full.java:88)\n",
      "\tat org.terrier.querying.LocalManager$ApplyLocalMatching.process(LocalManager.java:518)\n",
      "\tat org.terrier.querying.LocalManager.runSearchRequest(LocalManager.java:895)\n",
      "Caused by: java.lang.ClassCastException: class org.terrier.structures.postings.bit.FieldIterablePosting cannot be cast to class org.terrier.structures.postings.BlockPosting (org.terrier.structures.postings.bit.FieldIterablePosting and org.terrier.structures.postings.BlockPosting are in unnamed module of loader 'app')\n",
      "\tat org.terrier.structures.postings.PhraseIterablePosting.<init>(PhraseIterablePosting.java:58)\n",
      "\tat org.terrier.matching.matchops.PhraseOp.createFinalPostingIterator(PhraseOp.java:83)\n",
      "\t... 7 common frames omitted\n",
      "18:32:03.724 [main] ERROR org.terrier.querying.LocalManager - Problem running Matching, returning empty result set as query 3\n",
      "java.io.IOException: This index does not support blocks\n",
      "\tat org.terrier.matching.matchops.PhraseOp.createFinalPostingIterator(PhraseOp.java:85)\n",
      "\tat org.terrier.matching.matchops.MultiTermOp.getPostingIterator(MultiTermOp.java:131)\n",
      "\tat org.terrier.matching.matchops.MultiTermOp.getMatcher(MultiTermOp.java:147)\n",
      "\tat org.terrier.matching.PostingListManager.<init>(PostingListManager.java:304)\n",
      "\tat org.terrier.matching.PostingListManager.<init>(PostingListManager.java:282)\n",
      "\tat org.terrier.matching.daat.Full.match(Full.java:88)\n",
      "\tat org.terrier.querying.LocalManager$ApplyLocalMatching.process(LocalManager.java:518)\n",
      "\tat org.terrier.querying.LocalManager.runSearchRequest(LocalManager.java:895)\n",
      "Caused by: java.lang.ClassCastException: class org.terrier.structures.postings.bit.FieldIterablePosting cannot be cast to class org.terrier.structures.postings.BlockPosting (org.terrier.structures.postings.bit.FieldIterablePosting and org.terrier.structures.postings.BlockPosting are in unnamed module of loader 'app')\n",
      "\tat org.terrier.structures.postings.PhraseIterablePosting.<init>(PhraseIterablePosting.java:58)\n",
      "\tat org.terrier.matching.matchops.PhraseOp.createFinalPostingIterator(PhraseOp.java:83)\n",
      "\t... 7 common frames omitted\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BR(BM25): 100%|██████████| 3/3 [00:00<00:00, 16.40q/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done. Here are the first 10 entries of the run\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>docid</th>\n",
       "      <th>docno</th>\n",
       "      <th>rank</th>\n",
       "      <th>score</th>\n",
       "      <th>qid</th>\n",
       "      <th>query</th>\n",
       "      <th>query_0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [docid, docno, rank, score, qid, query, query_0]\n",
       "Index: []"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Now we do the retrieval...')\n",
    "run_sdm = retrieval_pipeline(topics)\n",
    "\n",
    "print('Done. Here are the first 10 entries of the run')\n",
    "run_sdm.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5. Save in the file. \n",
    "This step should be implemented for doing the evaluation in our complex retrieval system, but we will do the evaluation here, so it is not necessary, that is why it is commented."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we add the result to our run.txt\n",
    "#persist_and_normalize_run(run_sdm,  default_output='../runs', system_name='BM25-SDM', depth=1000)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 6. Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BR(BM25): 100%|██████████| 68/68 [00:02<00:00, 27.34q/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "unknown run format: DataFrame missing columns: ['score', 'doc_id'] (found ['query_id', 'query', 'query_0'])",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mpt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mExperiment\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretr_systems\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mbm25\u001b[49m\u001b[43m,\u001b[49m\u001b[43msdm\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtopics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpt_dataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_topics\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtext\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mqrels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpt_dataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_qrels\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnames\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mBM25\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mBM25_SMD\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_metrics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrecall_1000\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mndcg_cut_5\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mndcg_cut.10\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrecip_rank\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyterrier/pipelines.py:471\u001b[0m, in \u001b[0;36mExperiment\u001b[0;34m(retr_systems, topics, qrels, eval_metrics, names, perquery, dataframe, batch_size, filter_by_qrels, filter_by_topics, baseline, test, correction, correction_alpha, highlight, round, verbose, save_dir, save_mode, **kwargs)\u001b[0m\n\u001b[1;32m    468\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m save_dir \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    469\u001b[0m     save_file \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(save_dir, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.res.gz\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m name)\n\u001b[0;32m--> 471\u001b[0m time, evalMeasuresDict \u001b[38;5;241m=\u001b[39m \u001b[43m_run_and_evaluate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    472\u001b[0m \u001b[43m    \u001b[49m\u001b[43msystem\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtopics\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mqrels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_metrics\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    473\u001b[0m \u001b[43m    \u001b[49m\u001b[43mperquery\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mperquery\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbaseline\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    474\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    475\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbackfill_qids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mall_topic_qids\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mperquery\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    476\u001b[0m \u001b[43m    \u001b[49m\u001b[43msave_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msave_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    477\u001b[0m \u001b[43m    \u001b[49m\u001b[43msave_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msave_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    478\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpbar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpbar\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    480\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m baseline \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    481\u001b[0m     evalDictsPerQ\u001b[38;5;241m.\u001b[39mappend(evalMeasuresDict)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyterrier/pipelines.py:205\u001b[0m, in \u001b[0;36m_run_and_evaluate\u001b[0;34m(system, topics, qrels, metrics, pbar, save_mode, save_file, perquery, batch_size, backfill_qids)\u001b[0m\n\u001b[1;32m    202\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(res) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    203\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m topics, but no results received from \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (\u001b[38;5;28mlen\u001b[39m(topics), \u001b[38;5;28mstr\u001b[39m(system)) )\n\u001b[0;32m--> 205\u001b[0m     evalMeasuresDict \u001b[38;5;241m=\u001b[39m \u001b[43m_ir_measures_to_dict\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    206\u001b[0m \u001b[43m        \u001b[49m\u001b[43mir_measures\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miter_calc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmetrics\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mqrels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mres\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrename\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_irmeasures_columns\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    207\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmetrics\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    208\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrev_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    209\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_q\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    210\u001b[0m \u001b[43m        \u001b[49m\u001b[43mperquery\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    211\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbackfill_qids\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    212\u001b[0m     pbar\u001b[38;5;241m.\u001b[39mupdate()\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    214\u001b[0m     \u001b[38;5;66;03m#transformer, evaluate queries in batches\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyterrier/pipelines.py:134\u001b[0m, in \u001b[0;36m_ir_measures_to_dict\u001b[0;34m(seq, metrics, rev_mapping, num_q, perquery, backfill_qids)\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;66;03m# measure -> value\u001b[39;00m\n\u001b[1;32m    133\u001b[0m rtr \u001b[38;5;241m=\u001b[39m {rev_mapping\u001b[38;5;241m.\u001b[39mget(m, \u001b[38;5;28mstr\u001b[39m(m)): m\u001b[38;5;241m.\u001b[39maggregator() \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m metrics}\n\u001b[0;32m--> 134\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m seq:\n\u001b[1;32m    135\u001b[0m     metric \u001b[38;5;241m=\u001b[39m m\u001b[38;5;241m.\u001b[39mmeasure\n\u001b[1;32m    136\u001b[0m     metric \u001b[38;5;241m=\u001b[39m rev_mapping\u001b[38;5;241m.\u001b[39mget(metric, \u001b[38;5;28mstr\u001b[39m(metric))\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/ir_measures/providers/base.py:22\u001b[0m, in \u001b[0;36mEvaluator.iter_calc\u001b[0;34m(self, run)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;124;03mYields per-topic metrics this run.\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     21\u001b[0m expected_measure_qids \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(itertools\u001b[38;5;241m.\u001b[39mproduct(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmeasures, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mqrel_qids))\n\u001b[0;32m---> 22\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m metric \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iter_calc(run):\n\u001b[1;32m     23\u001b[0m     expected_measure_qids\u001b[38;5;241m.\u001b[39mdiscard((metric\u001b[38;5;241m.\u001b[39mmeasure, metric\u001b[38;5;241m.\u001b[39mquery_id))\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m metric\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/ir_measures/providers/pytrec_eval_provider.py:201\u001b[0m, in \u001b[0;36mPytrecEvalEvaluator._iter_calc\u001b[0;34m(self, run)\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_iter_calc\u001b[39m(\u001b[38;5;28mself\u001b[39m, run):\n\u001b[1;32m    200\u001b[0m     \u001b[38;5;66;03m# Convert qrels to dict_of_dict (input format used by pytrec_eval)\u001b[39;00m\n\u001b[0;32m--> 201\u001b[0m     run \u001b[38;5;241m=\u001b[39m \u001b[43mir_measures\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mutil\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mRunConverter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mas_dict_of_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    202\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m invoker \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minvokers:\n\u001b[1;32m    203\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m invoker\u001b[38;5;241m.\u001b[39miter_calc(run)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/ir_measures/util.py:198\u001b[0m, in \u001b[0;36mRunConverter.as_dict_of_dict\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    196\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    197\u001b[0m     result \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m--> 198\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m scored_doc \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mas_namedtuple_iter():\n\u001b[1;32m    199\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m scored_doc\u001b[38;5;241m.\u001b[39mquery_id \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m result:\n\u001b[1;32m    200\u001b[0m             result[scored_doc\u001b[38;5;241m.\u001b[39mquery_id] \u001b[38;5;241m=\u001b[39m {}\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/ir_measures/util.py:215\u001b[0m, in \u001b[0;36mRunConverter.as_namedtuple_iter\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m (ScoredDoc(sd\u001b[38;5;241m.\u001b[39mquery_id, sd\u001b[38;5;241m.\u001b[39mdoc_id, sd\u001b[38;5;241m.\u001b[39mscore) \u001b[38;5;28;01mfor\u001b[39;00m sd \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrun\u001b[38;5;241m.\u001b[39mitertuples())\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m t \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUNKNOWN\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m--> 215\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124munknown run format: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00merr\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: unknown run format: DataFrame missing columns: ['score', 'doc_id'] (found ['query_id', 'query', 'query_0'])"
     ]
    }
   ],
   "source": [
    "pt.Experiment(\n",
    "    retr_systems=[bm25,sdm],\n",
    "    topics=pt_dataset.get_topics('text'),\n",
    "    qrels=pt_dataset.get_qrels(),\n",
    "    names=['BM25', 'BM25_SMD'],\n",
    "    eval_metrics=['recall_1000', 'ndcg_cut_5', 'ndcg_cut.10', 'recip_rank']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
